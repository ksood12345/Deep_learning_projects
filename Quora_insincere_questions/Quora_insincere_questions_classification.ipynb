{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reported-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identical-emphasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    qid                                      question_text  \\\n",
      "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
      "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
      "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
      "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
      "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sunrise-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1      80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confidential-marker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    How did Quebec nationalists see their province...\n",
      "1    Do you have an adopted dog, how would you enco...\n",
      "2    Why does velocity affect time? Does velocity a...\n",
      "3    How did Otto von Guericke used the Magdeburg h...\n",
      "4    Can I convert montra helicon D to a mountain b...\n",
      "Name: question_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = df['question_text']\n",
    "y = df['target']\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to preprocess text\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "def preprocess(doc):\n",
    "  doc = re.sub(r'\\W', ' ',str(doc))\n",
    "  doc = doc.lower()                 # Converting to lowercase\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  doc = re.sub(cleanr, ' ',str(doc))        #Removing HTML tags\n",
    "  doc = re.sub(r'[?|!|\\'|\"|#]',r'',str(doc))\n",
    "  doc = re.sub(r'[.|,|)|(|\\|/]',r' ',str(doc))\n",
    "  doc=re.sub(r'\\s+', ' ',str(doc),flags=re.I)\n",
    "  doc=re.sub(r'^b\\s+', ' ',str(doc))\n",
    "  doc = re.sub(r'\\[[0-9]*\\]', ' ', doc)\n",
    "  doc = re.sub(r'\\s+', ' ',doc)\n",
    "  # Removing special characters and digits\n",
    "  doc = re.sub('[^a-zA-Z]', ' ', doc )\n",
    "  doc = re.sub(r'\\s+', ' ', doc)\n",
    "  #doc_list = nltk.sent_tokenize(doc)\n",
    "  stopwords = nltk.corpus.stopwords.words('english')\n",
    "  #Lemmatization\n",
    "  tokens=doc.split()\n",
    "  tokens=[lemma.lemmatize(word) for word in tokens]\n",
    "  tokens=[word for word in tokens if word not in stopwords]\n",
    "  \n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the text\n",
    "messages = X.copy()\n",
    "corpus=[]\n",
    "for i in range(len(messages)) :\n",
    "    tokens=preprocess(messages['question_text'][i])\n",
    "    tokens=' '.join(tokens)\n",
    "    corpus.append(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the maximum length\n",
    "max_length = max([len(corpus[i].split(' ')) for i in range(len(corpus))])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the vocab size\n",
    "vocab = set()\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    tokens = corpus[i].split(' ')\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the vocab size\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# one-hot encoding the messages\n",
    "one_hot_encoding = [one_hot(sent, vocab_size) for sent in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the sequences to the same length\n",
    "padded_sentences = pad_sequences(one_hot_encoding, padding = 'pre', maxlen = max_length)\n",
    "\n",
    "print(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our benchmark model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_features, input_length = max_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating second deep learning model for comparing the performance\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(vocab_size, embedding_vector_features, input_length = max_length))\n",
    "model1.add(Bidirectional(LSTM(100)))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cretaing stacked LSTM model for comparison\n",
    "model2=Sequential()\n",
    "model2.add(Embedding(vocab_size, embedding_vector_features, input_length = max_length))\n",
    "model2.add(LSTM(50,return_sequences=True))\n",
    "model2.add(LSTM(50,return_sequences=True))\n",
    "model2.add(LSTM(50))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# creating our final dataset for training the model\n",
    "X_final = np.array(padded_sentences)\n",
    "y_final = np.array(y)\n",
    "\n",
    "(X_final.shape, y_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting the data into training, validation and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.2, random_state = 123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model and validating on the validation set\n",
    "history = model2.fit(X_train, y_train, validation_data = (X_val, y_val),epochs = 10,batch_size = 64, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting the model history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on the test set\n",
    "y_pred1 = model2.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
